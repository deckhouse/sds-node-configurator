name: Build and push for dev

env:
  MODULES_REGISTRY: ${{ vars.DEV_REGISTRY }}
  CI_COMMIT_REF_NAME: ${{ github.ref_name }}
  MODULES_MODULE_NAME: ${{ vars.MODULE_NAME }}
  MODULES_MODULE_SOURCE: ${{ vars.DEV_MODULE_SOURCE }}
  MODULES_REGISTRY_LOGIN: ${{ vars.DEV_MODULES_REGISTRY_LOGIN }}
  MODULES_REGISTRY_PASSWORD: ${{ secrets.DEV_MODULES_REGISTRY_PASSWORD }}
  GOPROXY: ${{ secrets.GOPROXY }}
  SOURCE_REPO: ${{ secrets.SOURCE_REPO }}
  SOURCE_REPO_SSH_KEY: ${{ secrets.SOURCE_REPO_SSH_KEY }}
  BASE_IMAGES_VERSION: "v0.5.25"

on:
  #pull_request:
  # call from trivy_image_check.yaml, which in turn call from pull_request
  # https://stackoverflow.com/a/71489231
  workflow_call:
    inputs:
      svace_enabled:
        description: "Enable svace build and analyze"
        type: boolean
        required: false
  push:
    branches:
      - main

defaults:
  run:
    shell: bash

concurrency:
  group: "${{ github.workflow }}-${{ github.event.number || github.ref }}"
  cancel-in-progress: true

jobs:
  lint:
    runs-on: [self-hosted, regular]
    continue-on-error: true
    name: Lint
    steps:
      - uses: actions/checkout@v4
      - name: Copy openapi/values_ce.yaml to openapi/values.yaml
        run: |
          if [ -f openapi/values_ce.yaml ]; then
            cp -f openapi/values_ce.yaml openapi/values.yaml
          fi
      - uses: deckhouse/modules-actions/lint@main
        env:
          DMT_METRICS_URL: ${{ secrets.DMT_METRICS_URL }}
          DMT_METRICS_TOKEN: ${{ secrets.DMT_METRICS_TOKEN }}
      - name: Copy openapi/values_ee.yaml to openapi/values.yaml
        run: |
          if [ -f openapi/values_ee.yaml ]; then
            cp -f openapi/values_ee.yaml openapi/values.yaml
          fi
      - uses: deckhouse/modules-actions/lint@main
        env:
          DMT_METRICS_URL: ${{ secrets.DMT_METRICS_URL }}
          DMT_METRICS_TOKEN: ${{ secrets.DMT_METRICS_TOKEN }}

  set_edition:
    runs-on: [self-hosted, large]
    name: Set edition
    outputs:
      module_edition: ${{ steps.set-vars.outputs.MODULE_EDITION }}
    steps:
      - name: Get Pull Request Labels
        id: get-labels
        uses: actions/github-script@v7
        with:
          script: |
            if (context.eventName === "pull_request" || context.eventName === "pull_request_target" ) {
              const prNumber = context.payload.pull_request.number;
              const { data: labels } = await github.rest.issues.listLabelsOnIssue({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
              });
              return labels.map(label => label.name);
            } else {
              return [];
            }
          result-encoding: string

      - name: Set vars
        id: set-vars
        run: |
          # Select edition for build, default ee
          if echo "${{ steps.get-labels.outputs.result }}" | grep -q "edition/ce"; then
            echo "MODULE_EDITION=ce" >> "$GITHUB_OUTPUT"
          else
            echo "MODULE_EDITION=ee" >> "$GITHUB_OUTPUT"
          fi

  dev_setup_build:
    runs-on: [self-hosted, large]
    name: Build and Push images
    needs: [set_edition]
    env:
      MODULE_EDITION: ${{needs.set_edition.outputs.module_edition}}
    steps:
      - name: Set vars for PR
        if: ${{ github.ref_name != 'main' }}
        run: |
          MODULES_MODULE_TAG="$(echo pr${{ github.ref_name }} | sed 's/\/.*//g')"
          echo "MODULES_MODULE_TAG=$MODULES_MODULE_TAG" >> "$GITHUB_ENV"
      - name: Set vars for main
        if: ${{ github.ref_name == 'main' }}
        run: |
          echo "MODULES_MODULE_TAG=${{ github.ref_name }}" >> "$GITHUB_ENV"
      - name: Print vars
        run: |
          echo MODULES_REGISTRY=$MODULES_REGISTRY
          echo CI_COMMIT_REF_NAME=$CI_COMMIT_REF_NAME
          echo MODULES_MODULE_NAME=$MODULES_MODULE_NAME
          echo MODULES_MODULE_SOURCE=$MODULES_MODULE_SOURCE
          echo MODULES_MODULE_TAG=$MODULES_MODULE_TAG
          echo MODULE_EDITION=$MODULE_EDITION

      - uses: actions/checkout@v4

      - name: Download base images and auth prepare
        run: |
          wget https://fox.flant.com/api/v4/projects/deckhouse%2Fbase-images/packages/generic/base_images/$BASE_IMAGES_VERSION/base_images.yml -O base_images.yml
          cat base_images.yml

      - uses: deckhouse/modules-actions/setup@v4
        with:
          registry: ${{ vars.DEV_REGISTRY }}
          registry_login: ${{ vars.DEV_MODULES_REGISTRY_LOGIN }}
          registry_password: ${{ secrets.DEV_MODULES_REGISTRY_PASSWORD }}
      - uses: deckhouse/modules-actions/build@v4
        with:
          module_source: "${{ vars.DEV_MODULE_SOURCE }}"
          module_name: ${{ vars.MODULE_NAME }}
          module_tag: ${{ env.MODULES_MODULE_TAG }}
          source_repo: ${{ secrets.SOURCE_REPO }}
          source_repo_ssh_key: ${{ secrets.SOURCE_REPO_SSH_KEY }}
          svace_enabled: ${{ contains(github.event.pull_request.labels.*.name, 'analyze/svace') || github.event.inputs.svace_enabled }}
          svace_analyze_host: "${{ secrets.SVACE_ANALYZE_HOST }}"
          svace_analyze_ssh_user: "${{ secrets.SVACE_ANALYZE_SSH_USER }}"
          svace_analyze_ssh_key: "${{ secrets.SVACE_ANALYZE_SSH_PRIVATE_KEY }}"

  analyze_build:
    if: ${{ contains(github.event.pull_request.labels.*.name, 'analyze/svace') || github.event.inputs.svace_enabled == 'true' }}
    name: Analyze build
    runs-on: [self-hosted, large]
    needs:
      - dev_setup_build
    steps:
      - uses: deckhouse/modules-actions/svace_analyze@v4
        with:
          project_group: ${{ github.event.repository.name }}
          ci_commit_ref_name: ${{ github.event.pull_request.head.ref || github.ref_name }}
          ci_commit_hash: ${{ github.sha }}
          svace_analyze_host: "${{ secrets.SVACE_ANALYZE_HOST }}"
          svace_analyze_ssh_user: "${{ secrets.SVACE_ANALYZE_SSH_USER }}"
          svacer_url: "${{ secrets.SVACER_URL }}"
          svacer_import_user: "${{ secrets.SVACER_IMPORT_USER }}"
          svacer_import_password: "${{ secrets.SVACER_IMPORT_PASSWORD }}"
          svace_analyze_ssh_private_key: "${{ secrets.SVACE_ANALYZE_SSH_PRIVATE_KEY }}"

 # E2E smoke тесты - запускаются после сборки при наличии лейбла e2e-smoke-test
  run_e2e_smoke_tests:
    if: ${{ contains(github.event.pull_request.labels.*.name, 'e2e-smoke-test') }}
    name: Run E2E Smoke Tests
    runs-on: [self-hosted, regular]
    needs:
      - dev_setup_build
    steps:
      - name: Setup kubectl
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.E2E_CLUSTER_KUBECONFIG }}" | base64 -d > ~/.kube/e2e-cluster-config
          export KUBECONFIG=~/.kube/e2e-cluster-config
          
          # Проверка доступа к кластеру
          kubectl cluster-info
          kubectl get nodes

      - name: Create E2E test Job in cluster
        run: |
          export KUBECONFIG=~/.kube/e2e-cluster-config
          
          # Генерируем уникальное имя для job
          JOB_NAME="e2e-test-${{ vars.MODULE_NAME }}-${{ github.run_id }}"
          NAMESPACE="e2e-tests"
          
          # Создаем namespace если не существует
          kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
          
          # Создаем secrets для тестов
          kubectl create secret generic e2e-test-secrets \
            --from-literal=ssh-host="${{ secrets.SSH_HOST }}" \
            --from-literal=license="${{ secrets.DECKHOUSE_LICENSE }}" \
            --namespace=$NAMESPACE \
            --dry-run=client -o yaml | kubectl apply -f -
          
          # Создаем kubeconfig secret
          echo "${{ secrets.KUBECONFIG_HYPERVISOR }}" | base64 -d > /tmp/hypervisor-kubeconfig
          kubectl create secret generic e2e-kubeconfigs \
            --from-file=hypervisor=/tmp/hypervisor-kubeconfig \
            --namespace=$NAMESPACE \
            --dry-run=client -o yaml | kubectl apply -f -
          rm /tmp/hypervisor-kubeconfig
          
          # Создаем SSH key secret
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > /tmp/ssh-key
          kubectl create secret generic e2e-ssh-key \
            --from-file=id_rsa=/tmp/ssh-key \
            --namespace=$NAMESPACE \
            --dry-run=client -o yaml | kubectl apply -f -
          rm /tmp/ssh-key
          
          # Параметры для smoke тестов (быстрые, на hypervisor)
          TEST_ARGS="-v -timeout 30m -verbose -debug -stand metal -hypervisorkconfig /etc/e2e/kubeconfigs/hypervisor -sshhost \$(cat /etc/e2e/secrets/ssh-host) -sshkey /etc/e2e/ssh/id_rsa"
          
          # Smoke тесты - запускаем через -run чтобы фильтровать конкретные тесты
          MODULE_NAME="${{ vars.MODULE_NAME }}"
          if [[ "$MODULE_NAME" == *"sds-node-configurator"* ]]; then
            TEST_PATTERN="./tests/"
            TEST_RUN="-run '^(TestNodeHealthCheck|TestLvg)$'"
          elif [[ "$MODULE_NAME" == *"sds-replicated-volume"* ]]; then
            TEST_PATTERN="./tests/"
            TEST_RUN="-run '^(TestNodeHealthCheck|TestPVC)$'"
          elif [[ "$MODULE_NAME" == *"data-export"* ]]; then
            TEST_PATTERN="./tests/"
            TEST_RUN="-run '^(TestNodeHealthCheck|TestDataExport)$'"
          else
            TEST_PATTERN="./tests/"
            TEST_RUN="-run '^TestNodeHealthCheck$'"
          fi
          
          # Создаем Job манифест
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ${JOB_NAME}
            namespace: ${NAMESPACE}
            labels:
              app: e2e-tests
              module: ${{ vars.MODULE_NAME }}
              pr: "${{ github.event.pull_request.number }}"
              run-id: "${{ github.run_id }}"
          spec:
            ttlSecondsAfterFinished: 86400  # Удалить через 24 часа
            backoffLimit: 0  # Не перезапускать при ошибке
            template:
              metadata:
                labels:
                  app: e2e-tests
                  module: ${{ vars.MODULE_NAME }}
              spec:
                restartPolicy: Never
                containers:
                - name: e2e-tests
                  image: golang:1.24
                  command:
                  - /bin/bash
                  - -c
                  - |
                    set -e
                    echo "Cloning sds-e2e repository..."
                    git clone https://github.com/deckhouse/sds-e2e.git /workspace/sds-e2e
                    cd /workspace/sds-e2e/testkit_v2
                    
                    echo "Installing dependencies..."
                    go mod download
                    
                    echo "Running E2E tests..."
                    echo "Module: ${MODULE_NAME}"
                    echo "Test pattern: ${TEST_PATTERN}"
                    echo "Test run filter: ${TEST_RUN}"
                    echo "Test args: ${TEST_ARGS}"
                    
                    export LICENSE_KEY=\$(cat /etc/e2e/secrets/license)
                    go test ${TEST_ARGS} ${TEST_RUN} ${TEST_PATTERN}
                  env:
                  - name: MODULE_NAME
                    value: "${{ vars.MODULE_NAME }}"
                  - name: TEST_PATTERN
                    value: "${TEST_PATTERN}"
                  - name: TEST_RUN
                    value: "${TEST_RUN}"
                  - name: TEST_ARGS
                    value: "${TEST_ARGS}"
                  - name: MODULE_UNDER_TEST
                    value: "${{ vars.MODULE_NAME }}"
                  - name: TEST_TYPE
                    value: "smoke"
                  - name: PR_NUMBER
                    value: "${{ github.event.pull_request.number }}"
                  - name: COMMIT_SHA
                    value: "${{ github.sha }}"
                  volumeMounts:
                  - name: e2e-secrets
                    mountPath: /etc/e2e/secrets
                    readOnly: true
                  - name: e2e-kubeconfigs
                    mountPath: /etc/e2e/kubeconfigs
                    readOnly: true
                  - name: e2e-ssh-key
                    mountPath: /etc/e2e/ssh
                    readOnly: true
                  resources:
                    requests:
                      memory: "4Gi"
                      cpu: "2"
                    limits:
                      memory: "8Gi"
                      cpu: "4"
                volumes:
                - name: e2e-secrets
                  secret:
                    secretName: e2e-test-secrets
                - name: e2e-kubeconfigs
                  secret:
                    secretName: e2e-kubeconfigs
                - name: e2e-ssh-key
                  secret:
                    secretName: e2e-ssh-key
                    defaultMode: 0600
          EOF
          
          echo "Job ${JOB_NAME} created in namespace ${NAMESPACE}"
          echo "JOB_NAME=${JOB_NAME}" >> $GITHUB_ENV
          echo "NAMESPACE=${NAMESPACE}" >> $GITHUB_ENV

      - name: Wait for E2E tests to complete
        run: |
          export KUBECONFIG=~/.kube/e2e-cluster-config
          
          echo "Waiting for Job ${JOB_NAME} to complete..."
          
          # Ждем завершения Job (максимум 90 минут)
          kubectl wait --for=condition=complete --timeout=90m \
            job/${JOB_NAME} -n ${NAMESPACE} || true
          
          # Проверяем статус
          JOB_STATUS=$(kubectl get job ${JOB_NAME} -n ${NAMESPACE} -o jsonpath='{.status.conditions[0].type}')
          
          echo "Job status: ${JOB_STATUS}"
          
          # Получаем логи
          POD_NAME=$(kubectl get pods -n ${NAMESPACE} -l job-name=${JOB_NAME} -o jsonpath='{.items[0].metadata.name}')
          echo "Pod name: ${POD_NAME}"
          
          echo "=== E2E Test Logs ==="
          kubectl logs ${POD_NAME} -n ${NAMESPACE} || true
          echo "====================="
          
          # Проверяем успешность
          if [ "${JOB_STATUS}" != "Complete" ]; then
            echo "Job failed or timed out"
            exit 1
          fi
          
          echo "E2E tests completed successfully!"

      - name: Save test logs as artifact
        if: always()
        run: |
          export KUBECONFIG=~/.kube/e2e-cluster-config
          
          POD_NAME=$(kubectl get pods -n ${NAMESPACE} -l job-name=${JOB_NAME} -o jsonpath='{.items[0].metadata.name}')
          mkdir -p test-logs
          kubectl logs ${POD_NAME} -n ${NAMESPACE} > test-logs/e2e-test-logs.txt 2>&1 || true

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-smoke-test-results-${{ vars.MODULE_NAME }}-${{ github.run_id }}
          path: test-logs/
          retention-days: 7

      - name: Comment PR with results
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ job.status }}' === 'success' ? '✅' : '❌';
            const statusText = '${{ job.status }}' === 'success' ? 'passed' : 'failed';
            
            const comment = `## E2E Smoke Tests Results ${status}
            
            **Module:** ${{ vars.MODULE_NAME }}
            **Test Type:** Smoke tests
            **Job Name:** \`${process.env.JOB_NAME}\`
            **Namespace:** \`${process.env.NAMESPACE}\`
            
            Smoke tests ${statusText}!
            
            Tests were executed in a Kubernetes Job in the e2e cluster (hypervisor environment).
            
            <details>
            <summary>View Details</summary>
            
            - **Workflow:** ${{ github.workflow }}
            - **Run ID:** ${{ github.run_id }}
            - **Commit:** ${{ github.sha }}
            - **Triggered by:** \`e2e-smoke-test\` label
            - **Cluster:** E2E dedicated cluster
            - **Duration:** ~10-15 minutes
            
            **View logs in cluster:**
            \`\`\`bash
            kubectl logs -n ${process.env.NAMESPACE} -l job-name=${process.env.JOB_NAME}
            \`\`\`
            
            </details>`;
            
            if (context.eventName === "pull_request" || context.eventName === "pull_request_target") {
              github.rest.issues.createComment({
                issue_number: context.payload.pull_request.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

      - name: Cleanup test Job
        if: always()
        run: |
          export KUBECONFIG=~/.kube/e2e-cluster-config
          
          # Удаляем Job (Pod удалится автоматически)
          kubectl delete job ${JOB_NAME} -n ${NAMESPACE} --ignore-not-found=true || true
          
          echo "Cleaned up Job ${JOB_NAME} in namespace ${NAMESPACE}"
